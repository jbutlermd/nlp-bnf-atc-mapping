{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "import jellyfish as jf\n",
    "from fuzzywuzzy import utils\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "import py_stringmatching as sm\n",
    "\n",
    "config_file = '../config.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "def calculate_score(distance, x, y):\n",
    "    return round((1 - distance / max(len(x), len(y))) * 100)\n",
    "\n",
    "def extract(query, choices, processor=utils.full_process, scorer=jf.levenshtein_distance, limit=2, distance=True):\n",
    "    tmp = choices.to_frame('name')\n",
    "    tmp['name'] = tmp['name'].apply(lambda x: processor(x))\n",
    "    \n",
    "    tmp['distance'] = tmp['name'].apply(lambda x: scorer(processor(query), str(x)))\n",
    "    if distance:\n",
    "        tmp['score'] = tmp.apply(lambda x: calculate_score(x['distance'], query, x['name']), axis=1)\n",
    "    else:\n",
    "        tmp['score'] = tmp['distance'].apply(lambda x: round(x * 100))\n",
    "    \n",
    "    tmp.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "    \n",
    "    results = tmp[0:limit]\n",
    "    best_results = []\n",
    "    for key, value in results.iterrows():\n",
    "        # print(value['ATC level name'])\n",
    "        best_results.append((value['name'], value['score'], key))\n",
    "\n",
    "    return best_results\n",
    "\n",
    "def remove_stop_words(x):\n",
    "    x_tokenized = word_tokenize(x)\n",
    "    tokens_without_sw = [word for word in x_tokenized if not word in stopwords]\n",
    "    text_without_sw = \" \".join(tokens_without_sw)\n",
    "    return text_without_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config['DEFAULT']['output_dir'],'bnf_code_clean.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join('../data/test_analysis_set.csv'))\n",
    "atc_df = pd.read_csv(os.path.join('../data/rxnorm_atc_code_info.csv'))\n",
    "atc_df.columns = ['i', 'rxcui', 'rxaui', 'sab', 'tty', 'ATC code', 'ATC level name', 'suppress']\n",
    "atc_df.drop('i', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['normalized_name'] = df_test['bnf_chemical_substance'].apply(lambda x: utils.full_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = atc_df['ATC level name']\n",
    "tmp = s.to_frame('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['distance'] = tmp['name'].apply(lambda x: jf.jaro_distance('esomeprazole', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['distance'] = tmp['name'].apply(lambda x: jf.jaro_distance('esomeprazole', str(x)))\n",
    "tmp['score'] = tmp['distance'].apply(lambda x: round(x*100))\n",
    "#atc_df['score'] = atc_df.apply(lambda x: calculate_score(x['distance'], 'nizatidine', x['ATC level name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "tmp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_df['distance'] = atc_df['ATC level name'].apply(lambda x: jf.jaro_distance('esomeprazole', x))\n",
    "atc_df['score'] = atc_df['distance'].apply(lambda x: round(x*100))\n",
    "#atc_df['score'] = atc_df.apply(lambda x: calculate_score(x['distance'], 'nizatidine', x['ATC level name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tmp[0:5]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = [];\n",
    "\n",
    "for key,value in results.iterrows():\n",
    "    #print(value['ATC level name'])\n",
    "    best_results.append((value['name'], value['score'], key))\n",
    "    \n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract('Nizatidine', s, scorer=jf.jaro_winkler, limit=5, distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extract('nizatidine', s, scorer=fuzz.ratio, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sm.Cosine()\n",
    "ws = sm.WhitespaceTokenizer()\n",
    "qgram = sm.QgramTokenizer(prefix_pad='^', suffix_pad='!')\n",
    "scorer.get_sim_score(qgram.tokenize('nizatidine'),qgram.tokenize('mesna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_extract(query, choices, processor=utils.full_process, scorer=sm.Cosine, tokenizer=sm.WhitespaceTokenizer, limit=2, distance=True):\n",
    "    tmp = choices.to_frame('name')\n",
    "    tmp['name'] = tmp['name'].apply(lambda x: processor(x))\n",
    "    the_scorer = scorer()\n",
    "    set1 = tokenizer.tokenize(processor(query))\n",
    "    print(set1)\n",
    "    \n",
    "    tmp['distance'] = tmp['name'].apply(lambda x: the_scorer.get_sim_score(set1, tokenizer.tokenize(str(x))))\n",
    "    if distance:\n",
    "        tmp['score'] = tmp.apply(lambda x: calculate_score(x['distance'], query, x['name']), axis=1)\n",
    "    else:\n",
    "        tmp['score'] = tmp['distance'].apply(lambda x: round(x * 100))\n",
    "    \n",
    "    tmp.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "    \n",
    "    results = tmp[0:limit]\n",
    "    best_results = []\n",
    "    for key, value in results.iterrows():\n",
    "        # print(value['ATC level name'])\n",
    "        best_results.append((value['name'], value['score'], key))\n",
    "\n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_extract('metoprolol', s, scorer=sm.TverskyIndex, tokenizer=sm.QgramTokenizer(qval=2, prefix_pad='^', suffix_pad='!'), limit=15, distance=False)\n",
    "#set_extract('nizatidine hydrochloride', s, scorer=sm.Cosine, tokenizer=sm.WhitespaceTokenizer(), limit=5, distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = sm.JaroWinkler()\n",
    "hybrid = sm.MongeElkan(sim_func=scorer.get_sim_score)\n",
    "ws = sm.WhitespaceTokenizer()\n",
    "qgram = sm.QgramTokenizer(qval=2, prefix_pad='^', suffix_pad='!')\n",
    "hybrid.get_raw_score(qgram.tokenize('metoprolol tartarte'),qgram.tokenize('metoprolol succinate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_extract(query, choices, processor=utils.full_process, scorer=sm.JaroWinkler, tokenizer=sm.WhitespaceTokenizer, hybrid=sm.MongeElkan, limit=2, distance=True, threshold=None):\n",
    "    tmp = choices.to_frame('name')\n",
    "    tmp['name'] = tmp['name'].apply(lambda x: processor(x))\n",
    "    the_scorer = scorer()\n",
    "    \n",
    "    if threshold:\n",
    "        the_hybrid = hybrid(sim_func=the_scorer.get_sim_score, threshold=threshold)\n",
    "    else:\n",
    "        the_hybrid = hybrid(sim_func=the_scorer.get_sim_score)\n",
    "    set1 = tokenizer.tokenize(processor(query))\n",
    "    print(set1)\n",
    "    \n",
    "    tmp['distance'] = tmp['name'].apply(lambda x: the_hybrid.get_raw_score(set1, tokenizer.tokenize(str(x))))\n",
    "    if distance:\n",
    "        tmp['score'] = tmp.apply(lambda x: calculate_score(x['distance'], query, x['name']), axis=1)\n",
    "    else:\n",
    "        tmp['score'] = tmp['distance'].apply(lambda x: round(x * 100))\n",
    "    \n",
    "    tmp.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "    \n",
    "    results = tmp[0:limit]\n",
    "    best_results = []\n",
    "    for key, value in results.iterrows():\n",
    "        # print(value['ATC level name'])\n",
    "        best_results.append((value['name'], value['score'], key))\n",
    "\n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid_extract('Procaine', s, scorer=sm.HammingDistance, tokenizer=sm.QgramTokenizer(qval=4, prefix_pad='^', suffix_pad='!'), hybrid=sm.MongeElkan, limit=15, distance=False)\n",
    "#hybrid_extract('oxyprocaine', s, scorer=sm.HammingDistance, tokenizer=sm.WhitespaceTokenizer(), hybrid=sm.MongeElkan, limit=15, distance=False)\n",
    "hybrid_extract('Emtricitabine', s, scorer=sm.Editex, tokenizer=sm.DelimiterTokenizer(['/','&',' ']), hybrid=sm.MongeElkan, limit=15, distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hybrid_extract('metoprolol/thiazides', s, scorer=sm.Jaro, tokenizer=sm.QgramTokenizer(qval=4, prefix_pad='^', suffix_pad='!'), hybrid=sm.SoftTfIdf, limit=15, distance=False, threshold=0.9)\n",
    "hybrid_extract('ferrous sulfate', s, scorer=sm.Levenshtein, tokenizer=sm.WhitespaceTokenizer(), hybrid=sm.SoftTfIdf, limit=15, distance=False,threshold=0.9)\n",
    "#hybrid_extract('Emtricitabine & Tenofovir Alafenamide', s, scorer=sm.Levenshtein, tokenizer=sm.DelimiterTokenizer(['/','&',' ']), hybrid=sm.SoftTfIdf, limit=15, distance=False, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = jf.levenshtein_distance('Dave','David')\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
