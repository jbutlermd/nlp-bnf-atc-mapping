{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import configparser\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "config_file = '../config.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "y_test_ref = {\"tp\":1, \"fp\":0, \"fn\":1, \"tn\":0}\n",
    "y_pred_ref = {\"tp\":1, \"fp\":1, \"fn\":0, \"tn\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_confusion_matrix(y_test, y_pred, row):\n",
    "    for i in ['tp', 'fp', 'tn', 'fn']:\n",
    "        for j in range(int(row[i])):\n",
    "            y_test.append(y_test_ref[i])\n",
    "            y_pred.append(y_pred_ref[i])\n",
    "            \n",
    "def get_y_score(y_score, matches):\n",
    "    for i in matches:\n",
    "        tmp = eval(i)\n",
    "        for j in tmp:\n",
    "            y_score.append(j[1]/100)\n",
    "            #y_score.append((j[1]/100)/5)\n",
    "            #y_score.append(1/6896)\n",
    "            \n",
    "def get_y_true(y_test, y_pred):\n",
    "    return [x == y_pred[i] and x == True for i,x in enumerate(y_test)]\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, scorer):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC for %s' % scorer)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - ' + scorer)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scorer_title = [\"Levenshtein\", \"Damerau-Levenshtein\", \"Jaro\", \"Jaro-Winkler\", \"Hamming\"]\n",
    "scorer_title = [\"Ratio\", \"Partial Ratio\", \"Token Set Ratio\", \"Partial Token Set Ratio\",\n",
    "                \"Token Sort Ratio\", \"Partial Token Sort Ratio\"]\n",
    "for i, scorer in enumerate(scorer_title):\n",
    "    df = pd.read_excel(os.path.join('../output/method-fuzzywuzzy-results.xlsx'), sheet_name=scorer)\n",
    "    df.fillna(value='0', inplace=True)\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    y_score = []\n",
    "    df_records = df.to_dict('records')\n",
    "    [convert_confusion_matrix(y_test, y_pred, x) for x in df_records]\n",
    "    print('\\n\\n', scorer, '\\n')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    y = get_y_true(y_test, y_pred)\n",
    "    get_y_score(y_score, df.matches)\n",
    "    (fpr, tpr, thresholds) = roc_curve(y, y_score, drop_intermediate=False)\n",
    "    #print(y, y_score)\n",
    "    #print(fpr, tpr, thresholds)\n",
    "    plot_roc_curve(fpr, tpr, scorer)\n",
    "    print('ROC AUC:', roc_auc_score(y, y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_title = [\"2-grams Cosine\", \"2-grams Jaccard\", \"2-grams Dice\", \"2-grams Overlap Coefficient\", \"2-grams Tversky Index\", \"3-grams Cosine\", \"3-grams Jaccard\", \"3-grams Dice\"]\n",
    "for i, scorer in enumerate(scorer_title):\n",
    "    df = pd.read_excel(os.path.join('../output/method-token-based-results.xlsx'), sheet_name=scorer)\n",
    "    df.fillna(value='0', inplace=True)\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    y_score = []\n",
    "    df_records = df.to_dict('records')\n",
    "    [convert_confusion_matrix(y_test, y_pred, x) for x in df_records]\n",
    "    print('\\n\\n', scorer, '\\n')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    y = get_y_true(y_test, y_pred)\n",
    "    get_y_score(y_score, df.matches)\n",
    "    (fpr, tpr, thresholds) = roc_curve(y, y_score)\n",
    "    plot_roc_curve(fpr, tpr, scorer)\n",
    "    print('ROC AUC:', roc_auc_score(y, y_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
