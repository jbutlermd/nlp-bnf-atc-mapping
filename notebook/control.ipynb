{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Control using direct string compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "import jellyfish as jf\n",
    "from fuzzywuzzy import utils\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "config_file = '../config.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "def calculate_score(distance, x, y):\n",
    "    return round((1 - distance / max(len(x), len(y))) * 100)\n",
    "\n",
    "def extract(query, choices, processor=utils.full_process, scorer=jf.levenshtein_distance, limit=2, distance=True):\n",
    "    tmp = choices.to_frame('name')\n",
    "    tmp['name'] = tmp['name'].apply(lambda x: processor(x))\n",
    "    \n",
    "    tmp['distance'] = tmp['name'].apply(lambda x: scorer(remove_stop_words(processor(query)), str(x)))\n",
    "    if distance:\n",
    "        tmp['score'] = tmp.apply(lambda x: calculate_score(x['distance'], query, x['name']), axis=1)\n",
    "    else:\n",
    "        tmp['score'] = tmp['distance'].apply(lambda x: round(x * 100))\n",
    "    \n",
    "    tmp.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "    \n",
    "    results = tmp[0:limit]\n",
    "    best_results = []\n",
    "    for key, value in results.iterrows():\n",
    "        # print(value['ATC level name'])\n",
    "        best_results.append((value['name'], value['score'], key))\n",
    "\n",
    "    return best_results\n",
    "\n",
    "def remove_stop_words(x):\n",
    "    if x not in whitelist:\n",
    "        x_tokenized = x.split(\" \")\n",
    "        itertokens = iter(x_tokenized)\n",
    "        next(itertokens)\n",
    "        tokens_without_sw = [word for word in itertokens if not word in stop_words]\n",
    "        tokens_without_sw.insert(0,x_tokenized[0])\n",
    "        text_without_sw = \" \".join(tokens_without_sw)\n",
    "        return text_without_sw\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(config['DEFAULT']['output_dir'],'bnf_code_clean.csv'))\n",
    "stop_words = pd.read_csv(os.path.join('../data/stop_words.csv'), header=None)[0].values.tolist()\n",
    "whitelist = pd.read_csv(os.path.join('../data/whitelist.csv'), header=None)[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = pd.read_csv(os.path.join('../data/stop_words.csv'), header=None)[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join('../data/test_analysis_set.csv'))\n",
    "atc_df = pd.read_csv(os.path.join('../data/rxnorm_atc_code_info.csv'))\n",
    "atc_df.columns = ['i', 'rxcui', 'rxaui', 'sab', 'tty', 'ATC code', 'ATC level name', 'suppress']\n",
    "atc_df.drop('i', axis=1, inplace=True)\n",
    "atc_df['name_without_sw'] = atc_df['ATC level name'].apply(lambda x: remove_stop_words(x)) \n",
    "slim_atc_df = atc_df.loc[atc_df['tty'].isin(['IN','RXN_IN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_atc_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['normalized_name'] = df_test['bnf_chemical_substance'].apply(lambda x: utils.full_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atc_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slim_atc_df['ATC level name']\n",
    "tmp = s.to_frame('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = slim_atc_df['name_without_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_scorer(a, b):\n",
    "    if a.lower() == b.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract('metoprolol with diuretic', s, scorer=control_scorer, limit=5, distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract('ferrous sulfate', s, limit=10, distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(x):\n",
    "    if x not in whitelist:\n",
    "        x_tokenized = x.split(\" \")\n",
    "        itertokens = iter(x_tokenized)\n",
    "        next(itertokens)\n",
    "        tokens_without_sw = [word for word in itertokens if not word in stop_words]\n",
    "        tokens_without_sw.insert(0,x_tokenized[0])\n",
    "        text_without_sw = \" \".join(tokens_without_sw)\n",
    "        return text_without_sw\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = extract('Medroxyprogesterone Acetate', s, limit=5, distance=True)\n",
    "key2 = 'ATC level name'\n",
    "m_revised = []\n",
    "for row in m:\n",
    "    m_revised.append((slim_atc_df.loc[row[2], key2], row[1], row[2]))\n",
    "m_revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words('Medroxyprogesterone Acetate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stop_words('metoprolol Succinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_atc_df.loc[4928,'ATC level name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
